{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Table of Contents\n",
    "* [faster RCNN](#faster-RCNN)\n",
    "* [coco eval](#coco-eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import itertools\n",
    "from tqdm import tqdm as tqdm\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "pd.options.mode.chained_assignment = None\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import PIL.Image as Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# faster RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "THOR_targets = [\n",
    "                'AlarmClock',  \n",
    "                'Apple',\n",
    "                'BasketBall',\n",
    "                'Bowl',\n",
    "                'HousePlant',\n",
    "                'Laptop',\n",
    "                'Mug',\n",
    "                'RemoteControl',\n",
    "                'Television',\n",
    "                'Vase',\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO_INSTANCE_CATEGORY_NAMES = [c for c in COCO_INSTANCE_CATEGORY_NAMES_FULL if c in coco_to_thor] + ['__background__']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_to_thor = {\n",
    "    'clock': 'AlarmClock',\n",
    "    'sports ball': 'BasketBall',\n",
    "    'apple': 'Apple',\n",
    "    'bowl': 'Bowl',\n",
    "    'potted plant': 'HousePlant',\n",
    "    'laptop': 'Laptop',\n",
    "    'remote': 'RemoteControl',\n",
    "    'tv': 'Television',\n",
    "    'vase': 'Vase',\n",
    "    'cup': 'Mug'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# class ScaleBothSides(object):\n",
    "#     def __init__(self, size, interpolation=Image.BILINEAR):\n",
    "#         self.size = size\n",
    "#         self.interpolation = interpolation\n",
    "\n",
    "#     def __call__(self, img):\n",
    "#         return img.resize((self.size, self.size), self.interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./concord_ds/real/12225818185657.jpg'"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: real: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "ls real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 3)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(test_img) \n",
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(img_path, threshold):\n",
    "    img = Image.open(img_path) \n",
    "    transform = all_transforms\n",
    "    img = transform(img)\n",
    "    pred = model([img]) \n",
    "    pred_class = [COCO_INSTANCE_CATEGORY_NAMES[i] for i in list(pred[0]['labels'].numpy())]\n",
    "    pred_boxes = [[(i[0], i[1]), (i[2], i[3])] for i in list(pred[0]['boxes'].detach().numpy())]\n",
    "    pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "    pred_t = [pred_score.index(x) for x in pred_score if x > threshold][-1] \n",
    "    pred_boxes = pred_boxes[:pred_t+1]\n",
    "    pred_class = pred_class[:pred_t+1]\n",
    "    return pred_boxes, pred_class, pred_score[:pred_t+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, pred_cls, pred_scores = get_prediction(test_img, 0.5) # Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.95660466, 0.8861309, 0.54394394]"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(242.39453, 141.11584), (269.10144, 162.57094)],\n",
       " [(118.368225, 230.12021), (148.19176, 258.67926)],\n",
       " [(200.44073, 132.08434), (208.4292, 157.94707)]]"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traffic light', 'cup', 'bottle']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(242.39453, 141.11584), (269.10144, 162.57094)],\n",
       " [(118.368225, 230.12021), (148.19176, 258.67926)],\n",
       " [(200.44073, 132.08434), (208.4292, 157.94707)]]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['traffic light', 'cup', 'bottle']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def object_detection(img_path, threshold=0.5, rect_th=1, text_size=1, text_th=1):\n",
    "    boxes, pred_cls = get_prediction(img_path, threshold) # Get predictions\n",
    "    img = cv2.imread(img_path) \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(img, boxes[i][0], boxes[i][1],color=(255, 0, 255), thickness=rect_th) \n",
    "        cv2.putText(img,pred_cls[i], boxes[i][0],  cv2.FONT_HERSHEY_SIMPLEX, text_size, (255, 0, 255) ,thickness=text_th) \n",
    "        plt.imshow(img)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sim = './concord_ds/sim_exact/12225818185657.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-849729be8b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'img_path' is not defined"
     ]
    }
   ],
   "source": [
    "boxes, pred_cls = get_prediction(img_path, threshold) # Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-369-630bbe935fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mobject_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-135-d26df3a842a2>\u001b[0m in \u001b[0;36mobject_detection\u001b[0;34m(img_path, threshold, rect_th, text_size, text_th)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrect_th\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_th\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-134-c7cd33ac8d02>\u001b[0m in \u001b[0;36mget_prediction\u001b[0;34m(img_path, threshold)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpred_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mpred_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpred_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_score\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mpred_boxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_boxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpred_t\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mpred_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpred_t\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "object_detection(test_sim, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build coco formatted ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## det"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sports ball'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COCO_INSTANCE_CATEGORY_NAMES[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [],
   "source": [
    "base_gt_ds = {\n",
    "    'info': {'description': 'real_val_2_2',\n",
    "         'url': '',\n",
    "         'version': '1.0',\n",
    "         'year': 2019,\n",
    "         'contributor': 'AI2',\n",
    "         'date_created': '2019/11/14'},\n",
    "    'licenses': [],\n",
    "    'categories': [{'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
    "                 {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},\n",
    "                 {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},\n",
    "                 {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},\n",
    "                 {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},\n",
    "                 {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},\n",
    "                 {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},\n",
    "                 {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},\n",
    "                 {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'},\n",
    "                 {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
    "                 {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'},\n",
    "                 {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
    "                 {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'},\n",
    "                 {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
    "                 {'supercategory': 'animal', 'id': 16, 'name': 'bird'},\n",
    "                 {'supercategory': 'animal', 'id': 17, 'name': 'cat'},\n",
    "                 {'supercategory': 'animal', 'id': 18, 'name': 'dog'},\n",
    "                 {'supercategory': 'animal', 'id': 19, 'name': 'horse'},\n",
    "                 {'supercategory': 'animal', 'id': 20, 'name': 'sheep'},\n",
    "                 {'supercategory': 'animal', 'id': 21, 'name': 'cow'},\n",
    "                 {'supercategory': 'animal', 'id': 22, 'name': 'elephant'},\n",
    "                 {'supercategory': 'animal', 'id': 23, 'name': 'bear'},\n",
    "                 {'supercategory': 'animal', 'id': 24, 'name': 'zebra'},\n",
    "                 {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'},\n",
    "                 {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
    "                 {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
    "                 {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'},\n",
    "                 {'supercategory': 'accessory', 'id': 32, 'name': 'tie'},\n",
    "                 {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'},\n",
    "                 {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'},\n",
    "                 {'supercategory': 'sports', 'id': 35, 'name': 'skis'},\n",
    "                 {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'},\n",
    "                 {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'},\n",
    "                 {'supercategory': 'sports', 'id': 38, 'name': 'kite'},\n",
    "                 {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'},\n",
    "                 {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'},\n",
    "                 {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'},\n",
    "                 {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'},\n",
    "                 {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'},\n",
    "                 {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'},\n",
    "                 {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'},\n",
    "                 {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'},\n",
    "                 {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'},\n",
    "                 {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'},\n",
    "                 {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'},\n",
    "                 {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'},\n",
    "                 {'supercategory': 'food', 'id': 52, 'name': 'banana'},\n",
    "                 {'supercategory': 'food', 'id': 53, 'name': 'apple'},\n",
    "                 {'supercategory': 'food', 'id': 54, 'name': 'sandwich'},\n",
    "                 {'supercategory': 'food', 'id': 55, 'name': 'orange'},\n",
    "                 {'supercategory': 'food', 'id': 56, 'name': 'broccoli'},\n",
    "                 {'supercategory': 'food', 'id': 57, 'name': 'carrot'},\n",
    "                 {'supercategory': 'food', 'id': 58, 'name': 'hot dog'},\n",
    "                 {'supercategory': 'food', 'id': 59, 'name': 'pizza'},\n",
    "                 {'supercategory': 'food', 'id': 60, 'name': 'donut'},\n",
    "                 {'supercategory': 'food', 'id': 61, 'name': 'cake'},\n",
    "                 {'supercategory': 'furniture', 'id': 62, 'name': 'chair'},\n",
    "                 {'supercategory': 'furniture', 'id': 63, 'name': 'couch'},\n",
    "                 {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'},\n",
    "                 {'supercategory': 'furniture', 'id': 65, 'name': 'bed'},\n",
    "                 {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'},\n",
    "                 {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'},\n",
    "                 {'supercategory': 'electronic', 'id': 72, 'name': 'tv'},\n",
    "                 {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'},\n",
    "                 {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'},\n",
    "                 {'supercategory': 'electronic', 'id': 75, 'name': 'remote'},\n",
    "                 {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'},\n",
    "                 {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'},\n",
    "                 {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'},\n",
    "                 {'supercategory': 'appliance', 'id': 79, 'name': 'oven'},\n",
    "                 {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'},\n",
    "                 {'supercategory': 'appliance', 'id': 81, 'name': 'sink'},\n",
    "                 {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'},\n",
    "                 {'supercategory': 'indoor', 'id': 84, 'name': 'book'},\n",
    "                 {'supercategory': 'indoor', 'id': 85, 'name': 'clock'},\n",
    "                 {'supercategory': 'indoor', 'id': 86, 'name': 'vase'},\n",
    "                 {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'},\n",
    "                 {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'},\n",
    "                 {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'},\n",
    "                 {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./concord_ds/real/12225818185657.jpg'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_img_field(img, img_id):\n",
    "    base_image = {\n",
    "      'license': 0,\n",
    "      'file_name': img,\n",
    "      'coco_url': '',\n",
    "      'height': 300,\n",
    "      'width': 300,\n",
    "      'date_captured': '',\n",
    "      'flickr_url': '',\n",
    "      'id': img_id\n",
    "    }\n",
    "    return base_image\n",
    "\n",
    "def conv_det_bbox(box):\n",
    "    (x1, y1), (x2, y2) = box\n",
    "    new_box = [x1, y1, x2 - x1, y2 -y1]\n",
    "    new_box = [float(c) for c in new_box]\n",
    "    return new_box\n",
    "\n",
    "def build_ann_field(bbox, img_id, cat_id, aid):\n",
    "    form_bbox = conv_det_bbox(bbox)\n",
    "    base_anno = {'segmentation': [[]],\n",
    "                  'area': box_area(form_bbox),\n",
    "                  'iscrowd': 0,\n",
    "                  'image_id': img_id,\n",
    "                  'bbox': form_bbox,\n",
    "                  'category_id': cat_id,\n",
    "                  'id': aid}\n",
    "    return base_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "code_folding": [
     0,
     11
    ]
   },
   "outputs": [],
   "source": [
    "# def build_det_ds(raw_gt):\n",
    "#     base_gt_ds = {\n",
    "#     'info': {'description': 'sim_val_2_2',\n",
    "#          'url': '',\n",
    "#          'version': '1.0',\n",
    "#          'year': 2019,\n",
    "#          'contributor': 'AI2',\n",
    "#          'date_created': '2019/11/14'},\n",
    "#     'licenses': [],\n",
    "#     'images': [],\n",
    "#     'annotations': [],\n",
    "#     'categories': [{'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},\n",
    "#                  {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'},\n",
    "#                  {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
    "#                  {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'},\n",
    "#                  {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
    "#                  {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'},\n",
    "#                  {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
    "#                  {'supercategory': 'animal', 'id': 16, 'name': 'bird'},\n",
    "#                  {'supercategory': 'animal', 'id': 17, 'name': 'cat'},\n",
    "#                  {'supercategory': 'animal', 'id': 18, 'name': 'dog'},\n",
    "#                  {'supercategory': 'animal', 'id': 19, 'name': 'horse'},\n",
    "#                  {'supercategory': 'animal', 'id': 20, 'name': 'sheep'},\n",
    "#                  {'supercategory': 'animal', 'id': 21, 'name': 'cow'},\n",
    "#                  {'supercategory': 'animal', 'id': 22, 'name': 'elephant'},\n",
    "#                  {'supercategory': 'animal', 'id': 23, 'name': 'bear'},\n",
    "#                  {'supercategory': 'animal', 'id': 24, 'name': 'zebra'},\n",
    "#                  {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'},\n",
    "#                  {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
    "#                  {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
    "#                  {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'},\n",
    "#                  {'supercategory': 'accessory', 'id': 32, 'name': 'tie'},\n",
    "#                  {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'},\n",
    "#                  {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'},\n",
    "#                  {'supercategory': 'sports', 'id': 35, 'name': 'skis'},\n",
    "#                  {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'},\n",
    "#                  {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'},\n",
    "#                  {'supercategory': 'sports', 'id': 38, 'name': 'kite'},\n",
    "#                  {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'},\n",
    "#                  {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'},\n",
    "#                  {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'},\n",
    "#                  {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'},\n",
    "#                  {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'},\n",
    "#                  {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'},\n",
    "#                  {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'},\n",
    "#                  {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'},\n",
    "#                  {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'},\n",
    "#                  {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'},\n",
    "#                  {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'},\n",
    "#                  {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'},\n",
    "#                  {'supercategory': 'food', 'id': 52, 'name': 'banana'},\n",
    "#                  {'supercategory': 'food', 'id': 53, 'name': 'apple'},\n",
    "#                  {'supercategory': 'food', 'id': 54, 'name': 'sandwich'},\n",
    "#                  {'supercategory': 'food', 'id': 55, 'name': 'orange'},\n",
    "#                  {'supercategory': 'food', 'id': 56, 'name': 'broccoli'},\n",
    "#                  {'supercategory': 'food', 'id': 57, 'name': 'carrot'},\n",
    "#                  {'supercategory': 'food', 'id': 58, 'name': 'hot dog'},\n",
    "#                  {'supercategory': 'food', 'id': 59, 'name': 'pizza'},\n",
    "#                  {'supercategory': 'food', 'id': 60, 'name': 'donut'},\n",
    "#                  {'supercategory': 'food', 'id': 61, 'name': 'cake'},\n",
    "#                  {'supercategory': 'furniture', 'id': 62, 'name': 'chair'},\n",
    "#                  {'supercategory': 'furniture', 'id': 63, 'name': 'couch'},\n",
    "#                  {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'},\n",
    "#                  {'supercategory': 'furniture', 'id': 65, 'name': 'bed'},\n",
    "#                  {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'},\n",
    "#                  {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'},\n",
    "#                  {'supercategory': 'electronic', 'id': 72, 'name': 'tv'},\n",
    "#                  {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'},\n",
    "#                  {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'},\n",
    "#                  {'supercategory': 'electronic', 'id': 75, 'name': 'remote'},\n",
    "#                  {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'},\n",
    "#                  {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'},\n",
    "#                  {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'},\n",
    "#                  {'supercategory': 'appliance', 'id': 79, 'name': 'oven'},\n",
    "#                  {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'},\n",
    "#                  {'supercategory': 'appliance', 'id': 81, 'name': 'sink'},\n",
    "#                  {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'},\n",
    "#                  {'supercategory': 'indoor', 'id': 84, 'name': 'book'},\n",
    "#                  {'supercategory': 'indoor', 'id': 85, 'name': 'clock'},\n",
    "#                  {'supercategory': 'indoor', 'id': 86, 'name': 'vase'},\n",
    "#                  {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'},\n",
    "#                  {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'},\n",
    "#                  {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'},\n",
    "#                  {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n",
    "#     }\n",
    "#     running_ann_indx = 0\n",
    "#     for img_n, annos in raw_gt.items():\n",
    "# #         if len(annos) == 0:\n",
    "# #             continue\n",
    "#         img_id = img_n\n",
    "#         img_field = build_img_field(img_id, img_id)\n",
    "#         base_gt_ds['images'].append(img_field)\n",
    "#         for anno in annos:\n",
    "#             bbox, cat = anno\n",
    "#             anno_field = build_ann_field(bbox, img_id, COCO_INSTANCE_CATEGORY_NAMES.index(cat), running_ann_indx)\n",
    "#             running_ann_indx += 1\n",
    "#             base_gt_ds['annotations'].append(anno_field)\n",
    "#     return base_gt_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{\n",
    "\"image_id\": int, \"category_id\": int, \"bbox\": [x,y,width,height], \"score\": float,\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [],
   "source": [
    "def build_det_ds(raw_gt):\n",
    "    base_gt_ds = []\n",
    "    for img_n, annos in raw_gt.items():\n",
    "        for anno in annos:\n",
    "            bbox, cat = anno\n",
    "            cat_id = COCO_INSTANCE_CATEGORY_NAMES.index(cat)\n",
    "            form_bbox  = conv_det_bbox(bbox)\n",
    "            base_gt_ds.append({\n",
    "                            \"image_id\": img_n, \"category_id\": cat_id, \"bbox\":form_bbox, \"score\": 0.8,\n",
    "                            })\n",
    "    return base_gt_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_annos[image_id] = {'objects': get_results(\n",
    "                np.squeeze(boxes), np.squeeze(classes).astype(np.int32), np.squeeze(scores), category_index,\n",
    "                im_width, im_height)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('real_preds.pkl', 'rb') as f:\n",
    "    det_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_coco_ds = build_det_ds(det_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('real_val_2_2_det.json', 'w') as f:\n",
    "    json.dump(det_coco_ds, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./concord_ds/real/12225818185657.jpg'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('turk_obj_d_evel/loc_res.json', 'r') as f:\n",
    "    raw_gt = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_res = list(raw_gt.items())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'box': [1, 137, 37, 160], 'action': 'bowl'},\n",
       " {'box': [40, 134, 65, 166], 'action': 'mug'}]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clock': 'AlarmClock',\n",
       " 'sports ball': 'BasketBall',\n",
       " 'apple': 'Apple',\n",
       " 'bowl': 'Bowl',\n",
       " 'potted plant': 'HousePlant',\n",
       " 'laptop': 'Laptop',\n",
       " 'remote': 'RemoteControl',\n",
       " 'tv': 'Television',\n",
       " 'vase': 'Vase'}"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_to_thor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "thor_to_coco  = {v.lower(): k for k, v in coco_to_thor.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_img_field_gt(img, img_id):\n",
    "    base_image = {\n",
    "      'license': 0,\n",
    "      'file_name': img,\n",
    "      'coco_url': '',\n",
    "      'height': 300,\n",
    "      'width': 300,\n",
    "      'date_captured': '',\n",
    "      'flickr_url': '',\n",
    "      'id': img_id\n",
    "    }\n",
    "    return base_image\n",
    "\n",
    "def convert_gt_bbox(box):\n",
    "    x1, y1, x2, y2 = box\n",
    "    new_box = [x1, y1, x2 - x1, y2 -y1]\n",
    "    new_box = [float(c) for c in new_box]\n",
    "    return new_box\n",
    "\n",
    "def box_area(box):\n",
    "    return box[2] * box[3]\n",
    "\n",
    "def lookup_coco_cat_id(cat):\n",
    "    coco_cat = thor_to_coco[cat.lower()]\n",
    "    return COCO_INSTANCE_CATEGORY_NAMES.index(coco_cat)\n",
    "\n",
    "\n",
    "def build_ann_field_gt(bbox, img_id, cat_id, aid):\n",
    "    form_bbox = convert_gt_bbox(bbox)\n",
    "    base_anno = {'segmentation': [[]],\n",
    "                  'area': box_area(form_bbox),\n",
    "                  'iscrowd': 0,\n",
    "                  'image_id': img_id,\n",
    "                  'bbox': form_bbox,\n",
    "                  'category_id': cat_id,\n",
    "                  'id': aid}\n",
    "    return base_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "def build_gt_ds(raw_gt):\n",
    "    base_gt_ds = {\n",
    "    'info': {'description': 'real_val_2_2',\n",
    "         'url': '',\n",
    "         'version': '1.0',\n",
    "         'year': 2019,\n",
    "         'contributor': 'AI2',\n",
    "         'date_created': '2019/11/14'},\n",
    "    'licenses': [],\n",
    "    'images': [],\n",
    "    'annotations': [],\n",
    "    'categories': [{'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
    "                 {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},\n",
    "                 {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},\n",
    "                 {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},\n",
    "                 {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},\n",
    "                 {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},\n",
    "                 {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},\n",
    "                 {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},\n",
    "                 {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'},\n",
    "                 {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
    "                 {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'},\n",
    "                 {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
    "                 {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'},\n",
    "                 {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
    "                 {'supercategory': 'animal', 'id': 16, 'name': 'bird'},\n",
    "                 {'supercategory': 'animal', 'id': 17, 'name': 'cat'},\n",
    "                 {'supercategory': 'animal', 'id': 18, 'name': 'dog'},\n",
    "                 {'supercategory': 'animal', 'id': 19, 'name': 'horse'},\n",
    "                 {'supercategory': 'animal', 'id': 20, 'name': 'sheep'},\n",
    "                 {'supercategory': 'animal', 'id': 21, 'name': 'cow'},\n",
    "                 {'supercategory': 'animal', 'id': 22, 'name': 'elephant'},\n",
    "                 {'supercategory': 'animal', 'id': 23, 'name': 'bear'},\n",
    "                 {'supercategory': 'animal', 'id': 24, 'name': 'zebra'},\n",
    "                 {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'},\n",
    "                 {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
    "                 {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
    "                 {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'},\n",
    "                 {'supercategory': 'accessory', 'id': 32, 'name': 'tie'},\n",
    "                 {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'},\n",
    "                 {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'},\n",
    "                 {'supercategory': 'sports', 'id': 35, 'name': 'skis'},\n",
    "                 {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'},\n",
    "                 {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'},\n",
    "                 {'supercategory': 'sports', 'id': 38, 'name': 'kite'},\n",
    "                 {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'},\n",
    "                 {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'},\n",
    "                 {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'},\n",
    "                 {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'},\n",
    "                 {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'},\n",
    "                 {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'},\n",
    "                 {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'},\n",
    "                 {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'},\n",
    "                 {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'},\n",
    "                 {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'},\n",
    "                 {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'},\n",
    "                 {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'},\n",
    "                 {'supercategory': 'food', 'id': 52, 'name': 'banana'},\n",
    "                 {'supercategory': 'food', 'id': 53, 'name': 'apple'},\n",
    "                 {'supercategory': 'food', 'id': 54, 'name': 'sandwich'},\n",
    "                 {'supercategory': 'food', 'id': 55, 'name': 'orange'},\n",
    "                 {'supercategory': 'food', 'id': 56, 'name': 'broccoli'},\n",
    "                 {'supercategory': 'food', 'id': 57, 'name': 'carrot'},\n",
    "                 {'supercategory': 'food', 'id': 58, 'name': 'hot dog'},\n",
    "                 {'supercategory': 'food', 'id': 59, 'name': 'pizza'},\n",
    "                 {'supercategory': 'food', 'id': 60, 'name': 'donut'},\n",
    "                 {'supercategory': 'food', 'id': 61, 'name': 'cake'},\n",
    "                 {'supercategory': 'furniture', 'id': 62, 'name': 'chair'},\n",
    "                 {'supercategory': 'furniture', 'id': 63, 'name': 'couch'},\n",
    "                 {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'},\n",
    "                 {'supercategory': 'furniture', 'id': 65, 'name': 'bed'},\n",
    "                 {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'},\n",
    "                 {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'},\n",
    "                 {'supercategory': 'electronic', 'id': 72, 'name': 'tv'},\n",
    "                 {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'},\n",
    "                 {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'},\n",
    "                 {'supercategory': 'electronic', 'id': 75, 'name': 'remote'},\n",
    "                 {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'},\n",
    "                 {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'},\n",
    "                 {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'},\n",
    "                 {'supercategory': 'appliance', 'id': 79, 'name': 'oven'},\n",
    "                 {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'},\n",
    "                 {'supercategory': 'appliance', 'id': 81, 'name': 'sink'},\n",
    "                 {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'},\n",
    "                 {'supercategory': 'indoor', 'id': 84, 'name': 'book'},\n",
    "                 {'supercategory': 'indoor', 'id': 85, 'name': 'clock'},\n",
    "                 {'supercategory': 'indoor', 'id': 86, 'name': 'vase'},\n",
    "                 {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'},\n",
    "                 {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'},\n",
    "                 {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'},\n",
    "                 {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}]\n",
    "    }\n",
    "    running_ann_indx = 0\n",
    "    for img_n, annos in raw_gt.items():\n",
    "        if len(annos) == 0:\n",
    "            continue\n",
    "        img_id = img_n.split('.')[0]\n",
    "        img_field = build_img_field_gt(img_id, img_id)\n",
    "        base_gt_ds['images'].append(img_field)\n",
    "        for anno in annos:\n",
    "            if anno['action'] == 'none':\n",
    "                continue\n",
    "            anno_field = build_ann_field_gt(anno['box'], img_id, lookup_coco_cat_id(anno['action']), running_ann_indx)\n",
    "            running_ann_indx += 1\n",
    "            base_gt_ds['annotations'].append(anno_field)\n",
    "    return base_gt_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "real_val_2_2_gt = build_gt_ds(raw_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('real_val_2_2_gt.json', 'w') as f:\n",
    "    json.dump(real_val_2_2_gt, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image_names = [i['file_name'] + '.jpg' for i in real_val_2_2_gt['images']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('real_image_names.pkl', 'wb') as f:\n",
    "    pickle.dump(real_image_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "455"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(real_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 137.0, 36.0, 23.0]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_gt_bbox(samp_res[0]['box'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# coco eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchnet as tnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_mAP(det_boxes, det_labels, det_scores, true_boxes, true_labels, true_difficulties):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision (mAP) of detected objects.\n",
    "\n",
    "    See https://medium.com/@jonathan_hui/map-mean-average-precision-for-object-detection-45c121a31173 for an explanation\n",
    "\n",
    "    :param det_boxes: list of tensors, one tensor for each image containing detected objects' bounding boxes\n",
    "    :param det_labels: list of tensors, one tensor for each image containing detected objects' labels\n",
    "    :param det_scores: list of tensors, one tensor for each image containing detected objects' labels' scores\n",
    "    :param true_boxes: list of tensors, one tensor for each image containing actual objects' bounding boxes\n",
    "    :param true_labels: list of tensors, one tensor for each image containing actual objects' labels\n",
    "    :param true_difficulties: list of tensors, one tensor for each image containing actual objects' difficulty (0 or 1)\n",
    "    :return: list of average precisions for all classes, mean average precision (mAP)\n",
    "    \"\"\"\n",
    "    assert len(det_boxes) == len(det_labels) == len(det_scores) == len(true_boxes) == len(\n",
    "        true_labels) == len(\n",
    "        true_difficulties)  # these are all lists of tensors of the same length, i.e. number of images\n",
    "    n_classes = len(label_map)\n",
    "\n",
    "    # Store all (true) objects in a single continuous tensor while keeping track of the image it is from\n",
    "    true_images = list()\n",
    "    for i in range(len(true_labels)):\n",
    "        true_images.extend([i] * true_labels[i].size(0))\n",
    "    true_images = torch.LongTensor(true_images).to(\n",
    "        device)  # (n_objects), n_objects is the total no. of objects across all images\n",
    "    true_boxes = torch.cat(true_boxes, dim=0)  # (n_objects, 4)\n",
    "    true_labels = torch.cat(true_labels, dim=0)  # (n_objects)\n",
    "    true_difficulties = torch.cat(true_difficulties, dim=0)  # (n_objects)\n",
    "\n",
    "    assert true_images.size(0) == true_boxes.size(0) == true_labels.size(0)\n",
    "\n",
    "    # Store all detections in a single continuous tensor while keeping track of the image it is from\n",
    "    det_images = list()\n",
    "    for i in range(len(det_labels)):\n",
    "        det_images.extend([i] * det_labels[i].size(0))\n",
    "    det_images = torch.LongTensor(det_images).to(device)  # (n_detections)\n",
    "    det_boxes = torch.cat(det_boxes, dim=0)  # (n_detections, 4)\n",
    "    det_labels = torch.cat(det_labels, dim=0)  # (n_detections)\n",
    "    det_scores = torch.cat(det_scores, dim=0)  # (n_detections)\n",
    "\n",
    "    assert det_images.size(0) == det_boxes.size(0) == det_labels.size(0) == det_scores.size(0)\n",
    "\n",
    "    # Calculate APs for each class (except background)\n",
    "    average_precisions = torch.zeros((n_classes - 1), dtype=torch.float)  # (n_classes - 1)\n",
    "    for c in range(1, n_classes):\n",
    "        # Extract only objects with this class\n",
    "        true_class_images = true_images[true_labels == c]  # (n_class_objects)\n",
    "        true_class_boxes = true_boxes[true_labels == c]  # (n_class_objects, 4)\n",
    "        true_class_difficulties = true_difficulties[true_labels == c]  # (n_class_objects)\n",
    "        n_easy_class_objects = (1 - true_class_difficulties).sum().item()  # ignore difficult objects\n",
    "\n",
    "        # Keep track of which true objects with this class have already been 'detected'\n",
    "        # So far, none\n",
    "        true_class_boxes_detected = torch.zeros((true_class_difficulties.size(0)), dtype=torch.uint8).to(\n",
    "            device)  # (n_class_objects)\n",
    "\n",
    "        # Extract only detections with this class\n",
    "        det_class_images = det_images[det_labels == c]  # (n_class_detections)\n",
    "        det_class_boxes = det_boxes[det_labels == c]  # (n_class_detections, 4)\n",
    "        det_class_scores = det_scores[det_labels == c]  # (n_class_detections)\n",
    "        n_class_detections = det_class_boxes.size(0)\n",
    "        if n_class_detections == 0:\n",
    "            continue\n",
    "\n",
    "        # Sort detections in decreasing order of confidence/scores\n",
    "        det_class_scores, sort_ind = torch.sort(det_class_scores, dim=0, descending=True)  # (n_class_detections)\n",
    "        det_class_images = det_class_images[sort_ind]  # (n_class_detections)\n",
    "        det_class_boxes = det_class_boxes[sort_ind]  # (n_class_detections, 4)\n",
    "\n",
    "        # In the order of decreasing scores, check if true or false positive\n",
    "        true_positives = torch.zeros((n_class_detections), dtype=torch.float).to(device)  # (n_class_detections)\n",
    "        false_positives = torch.zeros((n_class_detections), dtype=torch.float).to(device)  # (n_class_detections)\n",
    "        for d in range(n_class_detections):\n",
    "            this_detection_box = det_class_boxes[d].unsqueeze(0)  # (1, 4)\n",
    "            this_image = det_class_images[d]  # (), scalar\n",
    "\n",
    "            # Find objects in the same image with this class, their difficulties, and whether they have been detected before\n",
    "            object_boxes = true_class_boxes[true_class_images == this_image]  # (n_class_objects_in_img)\n",
    "            object_difficulties = true_class_difficulties[true_class_images == this_image]  # (n_class_objects_in_img)\n",
    "            # If no such object in this image, then the detection is a false positive\n",
    "            if object_boxes.size(0) == 0:\n",
    "                false_positives[d] = 1\n",
    "                continue\n",
    "\n",
    "            # Find maximum overlap of this detection with objects in this image of this class\n",
    "            overlaps = find_jaccard_overlap(this_detection_box, object_boxes)  # (1, n_class_objects_in_img)\n",
    "            max_overlap, ind = torch.max(overlaps.squeeze(0), dim=0)  # (), () - scalars\n",
    "\n",
    "            # 'ind' is the index of the object in these image-level tensors 'object_boxes', 'object_difficulties'\n",
    "            # In the original class-level tensors 'true_class_boxes', etc., 'ind' corresponds to object with index...\n",
    "            original_ind = torch.LongTensor(range(true_class_boxes.size(0)))[true_class_images == this_image][ind]\n",
    "            # We need 'original_ind' to update 'true_class_boxes_detected'\n",
    "\n",
    "            # If the maximum overlap is greater than the threshold of 0.5, it's a match\n",
    "            if max_overlap.item() > 0.5:\n",
    "                # If the object it matched with is 'difficult', ignore it\n",
    "                if object_difficulties[ind] == 0:\n",
    "                    # If this object has already not been detected, it's a true positive\n",
    "                    if true_class_boxes_detected[original_ind] == 0:\n",
    "                        true_positives[d] = 1\n",
    "                        true_class_boxes_detected[original_ind] = 1  # this object has now been detected/accounted for\n",
    "                    # Otherwise, it's a false positive (since this object is already accounted for)\n",
    "                    else:\n",
    "                        false_positives[d] = 1\n",
    "            # Otherwise, the detection occurs in a different location than the actual object, and is a false positive\n",
    "            else:\n",
    "                false_positives[d] = 1\n",
    "\n",
    "        # Compute cumulative precision and recall at each detection in the order of decreasing scores\n",
    "        cumul_true_positives = torch.cumsum(true_positives, dim=0)  # (n_class_detections)\n",
    "        cumul_false_positives = torch.cumsum(false_positives, dim=0)  # (n_class_detections)\n",
    "        cumul_precision = cumul_true_positives / (\n",
    "                cumul_true_positives + cumul_false_positives + 1e-10)  # (n_class_detections)\n",
    "        cumul_recall = cumul_true_positives / n_easy_class_objects  # (n_class_detections)\n",
    "\n",
    "        # Find the mean of the maximum of the precisions corresponding to recalls above the threshold 't'\n",
    "        recall_thresholds = torch.arange(start=0, end=1.1, step=.1).tolist()  # (11)\n",
    "        precisions = torch.zeros((len(recall_thresholds)), dtype=torch.float).to(device)  # (11)\n",
    "        for i, t in enumerate(recall_thresholds):\n",
    "            recalls_above_t = cumul_recall >= t\n",
    "            if recalls_above_t.any():\n",
    "                precisions[i] = cumul_precision[recalls_above_t].max()\n",
    "            else:\n",
    "                precisions[i] = 0.\n",
    "        average_precisions[c - 1] = precisions.mean()  # c is in [1, n_classes - 1]\n",
    "\n",
    "    # Calculate Mean Average Precision (mAP)\n",
    "    mean_average_precision = average_precisions.mean().item()\n",
    "\n",
    "    # Keep class-wise average precisions in a dictionary\n",
    "    average_precisions = {rev_label_map[c + 1]: v for c, v in enumerate(average_precisions.tolist())}\n",
    "\n",
    "    return average_precisions, mean_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
